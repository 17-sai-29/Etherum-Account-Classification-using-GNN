{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with contract information saved to: C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\data.txt\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "file_path = r\"C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\2017-11-26.csv\"\n",
    "\n",
    "address_to_id = {}\n",
    "next_id = 1\n",
    "mapped_data = []\n",
    "\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    header = next(csv_reader) \n",
    "    \n",
    "   \n",
    "    from_address_column_index = 3 \n",
    "    to_address_column_index = 4   \n",
    "    value_column_index = 8        \n",
    "    from_is_contract_column_index = 6 \n",
    "    to_is_contract_column_index = 7 \n",
    "    \n",
    "    for row in csv_reader:\n",
    "        from_address = row[from_address_column_index]\n",
    "        to_address = row[to_address_column_index]\n",
    "        value = row[value_column_index]\n",
    "        from_is_contract = row[from_is_contract_column_index]\n",
    "        to_is_contract = row[to_is_contract_column_index]\n",
    "        \n",
    "       \n",
    "        if from_address not in address_to_id:\n",
    "            address_to_id[from_address] = next_id\n",
    "            next_id += 1\n",
    "        \n",
    "     \n",
    "        if to_address not in address_to_id:\n",
    "            address_to_id[to_address] = next_id\n",
    "            next_id += 1\n",
    "        \n",
    "      \n",
    "        from_address_id = address_to_id[from_address]\n",
    "        to_address_id = address_to_id[to_address]\n",
    "        mapped_data.append([from_address_id, to_address_id, value, from_is_contract, to_is_contract])\n",
    "\n",
    "\n",
    "output_file_path = r\"C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\data.txt\"\n",
    "\n",
    "with open(output_file_path, 'w') as file:\n",
    "    for entry in mapped_data:\n",
    "      \n",
    "        file.write('\\t'.join(map(str, entry)) + '\\n')\n",
    "\n",
    "print(f\"Data with contract information saved to: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full data for the largest connected subgraph has been saved to: C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\largest_connected_subgraph_with_data.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import networkx as nx\n",
    "\n",
    "edge_file = r\"C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\data.txt\"  \n",
    "\n",
    "\n",
    "output_file = os.path.join(os.path.dirname(edge_file), 'largest_connected_subgraph_with_data.txt')\n",
    "\n",
    "G = nx.DiGraph() \n",
    "\n",
    "\n",
    "with open(edge_file, 'r') as f:\n",
    "    for line in f:\n",
    "       \n",
    "        parts = line.strip().split()\n",
    "        from_node, to_node = parts[0], parts[1]\n",
    "        value = float(parts[2]) \n",
    "        from_is_contract = int(parts[3]) \n",
    "        to_is_contract = int(parts[4])\n",
    "        \n",
    "       \n",
    "        G.add_edge(from_node, to_node, weight=value, fromIsContract=from_is_contract, toIsContract=to_is_contract)\n",
    "\n",
    "\n",
    "weakly_connected_components = nx.weakly_connected_components(G)\n",
    "\n",
    "\n",
    "largest_component = max(weakly_connected_components, key=len)\n",
    "\n",
    "\n",
    "largest_subgraph = G.subgraph(largest_component)\n",
    "\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    for from_node, to_node, edge_data in largest_subgraph.edges(data=True):\n",
    "       \n",
    "        value = edge_data['weight']\n",
    "        from_is_contract = edge_data['fromIsContract']\n",
    "        to_is_contract = edge_data['toIsContract']\n",
    "        \n",
    "       \n",
    "        f.write(f\"{from_node}\\t{to_node}\\t{value}\\t{from_is_contract}\\t{to_is_contract}\\n\")\n",
    "\n",
    "print(f\"Full data for the largest connected subgraph has been saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renumbered graph data has been saved to: C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\renumbered_graph.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Read the data\n",
    "file_path = r\"C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\largest_connected_subgraph_with_data.txt\"  # Replace with your file path\n",
    "data = pd.read_csv(file_path, sep='\\t', header=None, names=['from', 'to', 'value', 'fromiscontract', 'toiscontract'])\n",
    "\n",
    "# Step 2: Get unique nodes and assign new node numbers sequentially\n",
    "unique_nodes = pd.unique(data[['from', 'to']].values.ravel())\n",
    "node_mapping = {node: idx + 1 for idx, node in enumerate(sorted(unique_nodes))}\n",
    "\n",
    "# Step 3: Replace the 'from' and 'to' columns with their new node numbers\n",
    "data['from'] = data['from'].map(node_mapping)\n",
    "data['to'] = data['to'].map(node_mapping)\n",
    "\n",
    "# Step 4: Save the modified data to a new text file\n",
    "output_file_path =os.path.join(os.path.dirname(file_path), 'renumbered_graph.txt')  # Replace with your desired output file path\n",
    "data.to_csv(output_file_path, sep='\\t', index=False, header=False)\n",
    "\n",
    "print(\"Renumbered graph data has been saved to:\", output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First two columns have been saved to: C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\extracted_columns.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Read the data\n",
    "file_path = r\"C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\renumbered_graph.txt\"  # Replace with your file path\n",
    "data = pd.read_csv(file_path, sep='\\t', header=None, names=['from', 'to', 'value', 'fromiscontract', 'toiscontract'])\n",
    "\n",
    "# Step 2: Extract only the first two columns\n",
    "first_two_columns = data[['from', 'to']]\n",
    "\n",
    "# Step 3: Save the extracted columns to a new text file\n",
    "output_file_path =os.path.join(os.path.dirname(file_path), 'extracted_columns.txt')  # Replace with your desired output file path\n",
    "first_two_columns.to_csv(output_file_path, sep='\\t', index=False, header=False)\n",
    "\n",
    "print(\"First two columns have been saved to:\", output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node contract status has been saved to C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\node_contract_status_connected.txt\n"
     ]
    }
   ],
   "source": [
    "# Paths to input and output files\n",
    "input_file = r\"C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\renumbered_graph.txt\"\n",
    "output_contract_status = os.path.join(os.path.dirname(input_file), \"node_contract_status_connected.txt\")  \n",
    "\n",
    "\n",
    "contract_info = {}\n",
    "\n",
    "\n",
    "with open(input_file, 'r') as file:\n",
    "    for line in file:\n",
    "        from_node, to_node, value, from_is_contract, to_is_contract = line.strip().split('\\t')\n",
    "        \n",
    "\n",
    "        if from_node not in contract_info:\n",
    "            contract_info[from_node] = int(from_is_contract)\n",
    "        else:\n",
    "            contract_info[from_node] = max(contract_info[from_node], int(from_is_contract))\n",
    "\n",
    "    \n",
    "        if to_node not in contract_info:\n",
    "            contract_info[to_node] = int(to_is_contract)\n",
    "        else:\n",
    "            contract_info[to_node] = max(contract_info[to_node], int(to_is_contract))\n",
    "\n",
    "\n",
    "with open(output_contract_status, 'w') as file:\n",
    "    for node, status in sorted(contract_info.items(), key=lambda x: int(x[0])):  \n",
    "        file.write(f\"{status}\\n\")  \n",
    "\n",
    "print(f\"Node contract status has been saved to {output_contract_status}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes with contract status 0: 182418\n",
      "Number of nodes with contract status 1: 12831\n"
     ]
    }
   ],
   "source": [
    "# Path\n",
    "contract_status_file = r\"C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\node_contract_status_connected.txt\"\n",
    "\n",
    "count_0 = 0\n",
    "count_1 = 0\n",
    "\n",
    "with open(contract_status_file, 'r') as file:\n",
    "    for line in file:\n",
    "        status = int(line.strip())\n",
    "        \n",
    "        if status == 0:\n",
    "            count_0 += 1\n",
    "        elif status == 1:\n",
    "            count_1 += 1\n",
    "\n",
    "print(f\"Number of nodes with contract status 0: {count_0}\")\n",
    "print(f\"Number of nodes with contract status 1: {count_1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file path: C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\renumbered_graph.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import networkx as nx\n",
    "\n",
    "edge_file = r\"C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\renumbered_graph.txt\"\n",
    "input_file = os.path.join(os.path.dirname(edge_file), r\"renumbered_graph.txt\")\n",
    "output_dir = os.path.dirname(input_file) \n",
    "\n",
    "print(\"Input file path:\", input_file)\n",
    "\n",
    "if not os.path.exists(input_file):\n",
    "    raise FileNotFoundError(f\"The input file does not exist: {input_file}\")\n",
    "\n",
    "G = nx.DiGraph()\n",
    "\n",
    "with open(input_file, 'r') as file:\n",
    "    for line_number, line in enumerate(file, start=1):\n",
    "        stripped_line = line.strip()\n",
    "        if not stripped_line:\n",
    "            continue\n",
    "        values = stripped_line.split()\n",
    "        if len(values) < 5:\n",
    "            print(f\"Skipping line {line_number} due to insufficient values: {stripped_line}\")\n",
    "            continue\n",
    "        try:\n",
    "            from_node, to_node, value, _, _ = values\n",
    "            value = float(value)\n",
    "            G.add_edge(from_node, to_node, weight=value)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error processing line {line_number}: {stripped_line} - {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-degree written to C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\indegreeconnected.txt\n"
     ]
    }
   ],
   "source": [
    "# In-degree\n",
    "in_degree_dict = dict(G.in_degree())\n",
    "output_in_degree = os.path.join(output_dir, \"indegreeconnected.txt\")\n",
    "with open(output_in_degree, 'w') as file:\n",
    "    for node, in_degree in sorted(in_degree_dict.items(), key=lambda x: int(x[0])):\n",
    "        file.write(f\"{in_degree}\\n\")\n",
    "print(f\"In-degree written to {output_in_degree}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-degree written to C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\outdegreeconnected.txt\n"
     ]
    }
   ],
   "source": [
    "# Out-degree\n",
    "out_degree_dict = dict(G.out_degree())\n",
    "output_out_degree = os.path.join(output_dir, \"outdegreeconnected.txt\")\n",
    "with open(output_out_degree, 'w') as file:\n",
    "    for node, out_degree in sorted(out_degree_dict.items(), key=lambda x: int(x[0])):\n",
    "        file.write(f\"{out_degree}\\n\")\n",
    "print(f\"Out-degree written to {output_out_degree}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted in-degree written to C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\weightedindegreeconnected.txt\n"
     ]
    }
   ],
   "source": [
    "# Weighted In-degree\n",
    "weighted_in_degree_dict = dict(G.in_degree(weight='weight'))\n",
    "output_weighted_in_degree = os.path.join(output_dir, \"weightedindegreeconnected.txt\")\n",
    "with open(output_weighted_in_degree, 'w') as file:\n",
    "    for node, weighted_in_degree in sorted(weighted_in_degree_dict.items(), key=lambda x: int(x[0])):\n",
    "        file.write(f\"{weighted_in_degree}\\n\")\n",
    "print(f\"Weighted in-degree written to {output_weighted_in_degree}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted out-degree written to C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\weightedoutdegreeconnected.txt\n"
     ]
    }
   ],
   "source": [
    "# Weighted Out-degree\n",
    "weighted_out_degree_dict = dict(G.out_degree(weight='weight'))\n",
    "output_weighted_out_degree = os.path.join(output_dir, \"weightedoutdegreeconnected.txt\")\n",
    "with open(output_weighted_out_degree, 'w') as file:\n",
    "    for node, weighted_out_degree in sorted(weighted_out_degree_dict.items(), key=lambda x: int(x[0])):\n",
    "        file.write(f\"{weighted_out_degree}\\n\")\n",
    "print(f\"Weighted out-degree written to {output_weighted_out_degree}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree centrality written to C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\degreecentralityconnected.txt\n"
     ]
    }
   ],
   "source": [
    "# Degree Centrality\n",
    "degree_centrality_dict = nx.degree_centrality(G)\n",
    "output_degree_centrality = os.path.join(output_dir, \"degreecentralityconnected.txt\")\n",
    "with open(output_degree_centrality, 'w') as file:\n",
    "    for node, degree_centrality in sorted(degree_centrality_dict.items(), key=lambda x: int(x[0])):\n",
    "        file.write(f\"{degree_centrality}\\n\")\n",
    "print(f\"Degree centrality written to {output_degree_centrality}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering coefficient written to C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\clusteringcoefficientconnected.txt\n"
     ]
    }
   ],
   "source": [
    "# Clustering Coefficient\n",
    "clustering_coefficient_dict = nx.clustering(G)\n",
    "output_clustering_coefficient = os.path.join(output_dir, \"clusteringcoefficientconnected.txt\")\n",
    "with open(output_clustering_coefficient, 'w') as file:\n",
    "    for node, clustering_coefficient in sorted(clustering_coefficient_dict.items(), key=lambda x: int(x[0])):\n",
    "        file.write(f\"{clustering_coefficient}\\n\")\n",
    "print(f\"Clustering coefficient written to {output_clustering_coefficient}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PageRank written to C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\pagerankconnected.txt\n"
     ]
    }
   ],
   "source": [
    "# PageRank\n",
    "pagerank_dict = nx.pagerank(G)\n",
    "output_pagerank = os.path.join(output_dir, \"pagerankconnected.txt\")\n",
    "with open(output_pagerank, 'w') as file:\n",
    "    for node, pagerank in sorted(pagerank_dict.items(), key=lambda x: int(x[0])):\n",
    "        file.write(f\"{pagerank}\\n\")\n",
    "print(f\"PageRank written to {output_pagerank}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated edges saved to C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\extractedcolumns1.txt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "input_file = r\"C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\extracted_columns.txt\" \n",
    "output_file = r\"C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\extractedcolumns1.txt\"  \n",
    "\n",
    "edges = np.loadtxt(input_file, dtype=int)\n",
    "\n",
    "edges_updated = edges - 1\n",
    "\n",
    "np.savetxt(output_file, edges_updated, fmt='%d')\n",
    "\n",
    "print(f\"Updated edges saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The graph is NOT strongly connected.\n",
      "Number of Strongly Connected Components: 148912\n",
      "\n",
      "Largest Strongly Connected Component Size: 21009\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "# Load the graph from a text file\n",
    "edge_file = r\"C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\7-11\\extractedcolumns1.txt\"\n",
    "\n",
    "try:\n",
    "    edges = np.loadtxt(edge_file, dtype=int)\n",
    "except Exception as e:\n",
    "    print(f\"Error reading edge file: {e}\")\n",
    "    exit()\n",
    "\n",
    "G = nx.DiGraph()\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "is_strongly_connected = nx.is_strongly_connected(G)\n",
    "\n",
    "if is_strongly_connected:\n",
    "    print(\"The graph is strongly connected.\")\n",
    "else:\n",
    "    print(\"The graph is NOT strongly connected.\")\n",
    "\n",
    "    strongly_connected_components = list(nx.strongly_connected_components(G))\n",
    "    print(f\"Number of Strongly Connected Components: {len(strongly_connected_components)}\")\n",
    "    \n",
    "if not is_strongly_connected:\n",
    "    largest_scc = max(strongly_connected_components, key=len)\n",
    "    print(f\"\\nLargest Strongly Connected Component Size: {len(largest_scc)}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for 2-12 :The graph is NOT strongly connected.\n",
    "Number of Strongly Connected Components: 221048\n",
    "\n",
    "Largest Strongly Connected Component Size: 34407\n",
    "\n",
    "for 6-11:the graph is NOT strongly connected.\n",
    "Number of Strongly Connected Components: 138265\n",
    "\n",
    "Largest Strongly Connected Component Size: 18543\n",
    "\n",
    "for 7-11:The graph is NOT strongly connected.\n",
    "Number of Strongly Connected Components: 148912\n",
    "\n",
    "Largest Strongly Connected Component Size: 21009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtracted values with non-negative results have been saved to: C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\subtracted_values.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path_1 = r\"C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\weightedindegreeconnected.txt\"\n",
    "file_path_2 = r\"C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\weightedoutdegreeconnected.txt\" \n",
    "\n",
    "data1 = pd.read_csv(file_path_1, header=None)\n",
    "data2 = pd.read_csv(file_path_2, header=None)\n",
    "\n",
    "result = data1[0] - data2[0]\n",
    "\n",
    "result = result.apply(lambda x: max(x, 0))\n",
    "\n",
    "output_file_path  = os.path.join(os.path.dirname(file_path_1), 'subtracted_values.txt') \n",
    "result.to_csv(output_file_path, index=False, header=False)\n",
    "\n",
    "print(\"Subtracted values with non-negative results have been saved to:\", output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized values written to C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\2--12\\feature5.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "input_file = r\"C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\2--12\\subtracted_values.txt\"\n",
    "\n",
    "with open(input_file, 'r') as infile:\n",
    "    values = [float(line.strip()) for line in infile]  \n",
    "\n",
    "max_value = max(values)\n",
    "\n",
    "output_file = os.path.join(os.path.dirname(input_file), 'feature5.txt')\n",
    "\n",
    "with open(output_file, 'w') as outfile:\n",
    "    for value in values:\n",
    "        normalized_value = value / max_value\n",
    "        outfile.write(f\"{normalized_value}\\n\")\n",
    "\n",
    "print(f\"Normalized values written to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized values written to C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\feature4.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the input file path\n",
    "input_file = r\"C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\clusteringcoefficientconnected.txt\"\n",
    "\n",
    "# Read the values from the file\n",
    "with open(input_file, 'r') as infile:\n",
    "    values = [float(line.strip()) for line in infile]  # Convert each line to a float\n",
    "\n",
    "# Find the maximum value\n",
    "max_value = max(values)\n",
    "\n",
    "# Create the output file path in the same folder as the input file\n",
    "output_file = os.path.join(os.path.dirname(input_file), 'feature4.txt')\n",
    "\n",
    "# Divide each value by the maximum and write to the new file\n",
    "with open(output_file, 'w') as outfile:\n",
    "    for value in values:\n",
    "        normalized_value = value / max_value\n",
    "        outfile.write(f\"{normalized_value}\\n\")\n",
    "\n",
    "print(f\"Normalized values written to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized values written to C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\feature3.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the input file path\n",
    "input_file = r\"C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\degreecentralityconnected.txt\"\n",
    "\n",
    "# Read the values from the file\n",
    "with open(input_file, 'r') as infile:\n",
    "    values = [float(line.strip()) for line in infile]  # Convert each line to a float\n",
    "\n",
    "# Find the maximum value\n",
    "max_value = max(values)\n",
    "\n",
    "# Create the output file path in the same folder as the input file\n",
    "output_file = os.path.join(os.path.dirname(input_file), 'feature3.txt')\n",
    "\n",
    "# Divide each value by the maximum and write to the new file\n",
    "with open(output_file, 'w') as outfile:\n",
    "    for value in values:\n",
    "        normalized_value = value / max_value\n",
    "        outfile.write(f\"{normalized_value}\\n\")\n",
    "\n",
    "print(f\"Normalized values written to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized values written to C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\feature6.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the input file path\n",
    "input_file = r\"C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\pagerankconnected.txt\"\n",
    "\n",
    "# Read the values from the file\n",
    "with open(input_file, 'r') as infile:\n",
    "    values = [float(line.strip()) for line in infile]  # Convert each line to a float\n",
    "\n",
    "# Find the maximum value\n",
    "max_value = max(values)\n",
    "\n",
    "# Create the output file path in the same folder as the input file\n",
    "output_file = os.path.join(os.path.dirname(input_file), 'feature6.txt')\n",
    "\n",
    "# Divide each value by the maximum and write to the new file\n",
    "with open(output_file, 'w') as outfile:\n",
    "    for value in values:\n",
    "        normalized_value = value / max_value\n",
    "        outfile.write(f\"{normalized_value}\\n\")\n",
    "\n",
    "print(f\"Normalized values written to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized values written to C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\feature2.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the input file path\n",
    "input_file = r\"C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\26-11\\outdegreeconnected.txt\"\n",
    "\n",
    "# Read the values from the file\n",
    "with open(input_file, 'r') as infile:\n",
    "    values = [float(line.strip()) for line in infile]  # Convert each line to a float\n",
    "\n",
    "# Find the maximum value\n",
    "max_value = max(values)\n",
    "\n",
    "# Create the output file path in the same folder as the input file\n",
    "output_file = os.path.join(os.path.dirname(input_file), 'feature2.txt')\n",
    "\n",
    "# Divide each value by the maximum and write to the new file\n",
    "with open(output_file, 'w') as outfile:\n",
    "    for value in values:\n",
    "        normalized_value = value / max_value\n",
    "        outfile.write(f\"{normalized_value}\\n\")\n",
    "\n",
    "print(f\"Normalized values written to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized values written to C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\2--12\\feature1.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the input file path\n",
    "input_file = r\"C:\\Users\\varun\\OneDrive\\Desktop\\MINIIII-2\\sk\\2--12\\indegreeconnected.txt\"\n",
    "\n",
    "# Read the values from the file\n",
    "with open(input_file, 'r') as infile:\n",
    "    values = [float(line.strip()) for line in infile]  # Convert each line to a float\n",
    "\n",
    "# Find the maximum value\n",
    "max_value = max(values)\n",
    "\n",
    "# Create the output file path in the same folder as the input file\n",
    "output_file = os.path.join(os.path.dirname(input_file), 'feature1.txt')\n",
    "\n",
    "# Divide each value by the maximum and write to the new file\n",
    "with open(output_file, 'w') as outfile:\n",
    "    for value in values:\n",
    "        normalized_value = value / max_value\n",
    "        outfile.write(f\"{normalized_value}\\n\")\n",
    "\n",
    "print(f\"Normalized values written to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MINI2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
